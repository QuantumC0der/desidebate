# Desi Debate System Configuration
#
# API Key Configuration:
# =================
# 1. Direct setting (not recommended for production):
#    api.openai.api_key: "your-api-key-here"
#
# 2. Environment variables (recommended):
#    Set environment variable OPENAI_API_KEY=your-api-key
#    Or modify api.openai.api_key_env to use a different environment variable name
#
# 3. Read from file:
#    api.openai.api_key_file: "path/to/your/api-key.txt"
#
# The system will try to load the API key in the above order
#

# System version
version: "2.0.0"

# System mode
mode: "production"  # development, production, debug

# Module activation settings
modules:
  rl:
    enabled: true
    type: "ppo"  # ppo, dqn, a2c
    config_file: "configs/rl.yaml"
    
  gnn:
    enabled: true
    type: "supervised"  # supervised, unsupervised
    config_file: "configs/gnn.yaml"
    
  rag:
    enabled: true
    type: "hybrid"  # simple, chroma, hybrid
    config_file: "configs/rag.yaml"

# Resource management
resources:
  # GPU settings
  gpu:
    enabled: true
    device: "cuda:0"
    memory_fraction: 0.8
    
  # CPU settings
  cpu:
    max_threads: 8
    affinity: null
    
  # Memory settings
  memory:
    max_usage_gb: 16
    cache_size_gb: 2

# API settings
api:
  # OpenAI API
  openai:
    # API Key settings (choose one)
    api_key: ""  # Set API key directly (not recommended for production)
    api_key_env: "OPENAI_API_KEY"  # Read from environment variable (recommended)
    api_key_file: ""  # Read API key from file (optional)
    
    # Connection settings
    max_retries: 3
    timeout: 30
    base_url: "https://api.openai.com/v1"  # API base URL
    
    # Model settings
    default_model: "gpt-3.5-turbo"
    max_tokens: 2048
    temperature: 0.7
    
  # Other APIs (future expansion)
  huggingface:
    enabled: false
    api_key: ""
    api_key_env: "HF_API_KEY"
    api_key_file: ""

# Data paths
paths:
  # Data directory
  data_dir: "data"
  raw_data: "data/raw"
  processed_data: "data/processed"
  
  # Model directory
  models_dir: "data/models"
  checkpoints_dir: "data/checkpoints"
  
  # Log directory
  logs_dir: "logs"
  
  # Cache directory
  cache_dir: "cache"

# Performance monitoring
monitoring:
  # System monitoring
  system_metrics:
    enabled: true
    interval: 60  # seconds
    
  # Model monitoring
  model_metrics:
    enabled: true
    track_latency: true
    track_accuracy: true
    
  # Alert settings
  alerts:
    enabled: false
    email: null
    slack_webhook: null

# Security settings
security:
  # API security
  api_security:
    rate_limiting: true
    max_requests_per_minute: 60
    
  # Data security
  data_security:
    encryption: false
    anonymization: true
    
  # Model security
  model_security:
    adversarial_detection: false
    output_filtering: true

# Experiment tracking
experiment_tracking:
  # Tool used
  tool: "tensorboard"  # tensorboard, mlflow, wandb, none
  
  # Tracking settings
  track_hyperparameters: true
  track_metrics: true
  track_artifacts: true
  
  # Experiment naming
  experiment_name_format: "{module}_{timestamp}"

# Deployment settings
deployment:
  # Server settings
  server:
    host: "0.0.0.0"
    port: 5000
    workers: 4
    
  # Load balancing
  load_balancing:
    enabled: false
    strategy: "round_robin"
    
  # Auto scaling
  auto_scaling:
    enabled: false
    min_instances: 1
    max_instances: 10

# Backup and recovery
backup:
  # Auto backup
  auto_backup:
    enabled: true
    frequency: "daily"  # hourly, daily, weekly
    retention_days: 30
    
  # Backup items
  backup_items:
    - models
    - configs
    - logs
    
  # Backup location
  backup_location: "backups/"

# Development settings
development:
  # Debug mode
  debug: false
  
  # Hot reload
  hot_reload: true
  
  # Test settings
  testing:
    unit_tests: true
    integration_tests: true
    coverage_threshold: 80