# RAG (Retrieval-Augmented Generation) Configuration

# Chroma Vector Database Settings
chroma:
  # Index path
  persist_directory: "data/chroma/social_debate"
  collection_name: "social_debate_collection"
  
  # Embedding model settings
  embedding:
    model: "text-embedding-3-small"
    dimension: 1536
    batch_size: 500
  
  # Retrieval parameters
  retrieval:
    top_k: 8
    score_threshold: 0.0
    include_metadata: true

# Simple Retriever Settings (backup)
simple_retriever:
  index_path: "src/rag/data/rag/simple_index.json"
  top_k: 3
  use_fuzzy_match: true

# Evidence Selection Settings
evidence_selection:
  # Scoring weights
  weights:
    relevance: 0.4
    quality: 0.3
    similarity: 0.3
  
  # Evidence type priority
  type_preference:
    - "research"
    - "expert_opinion"
    - "case_study"
    - "statistics"
    - "anecdotal"

# Index Building Settings
indexing:
  # Data source
  data_source: "data/raw/pairs.jsonl"
  
  # Document processing
  chunk_size: 1000
  chunk_overlap: 200
  min_chunk_length: 100
  
  # Metadata extraction
  extract_metadata: true
  metadata_fields:
    - "submission_id"
    - "score"
    - "author"
    - "created_utc"
    - "delta_awarded"
  
  # Quality filtering
  quality_filter:
    min_score: 10
    min_length: 50
    max_length: 5000

# Cache Settings
cache:
  enabled: true
  ttl: 3600  # seconds
  max_size: 1000

# Hybrid Retrieval Settings
hybrid_retrieval:
  # Enable hybrid retrieval
  enabled: true
  
  # Retrieval method weights
  weights:
    vector_search: 0.7    # Vector similarity retrieval
    bm25: 0.3            # BM25 keyword retrieval
  
  # BM25 parameters
  bm25_params:
    k1: 1.2
    b: 0.75

# Reranking Settings
reranking:
  # Enable reranking
  enabled: true
  
  # Reranking model
  model: "cross-encoder/ms-marco-MiniLM-L-6-v2"
  
  # Reranking parameters
  top_k_rerank: 20      # Top K results before reranking
  final_top_k: 5        # Final number of returned results

# Advanced Features
advanced_features:
  # Context-aware retrieval
  context_aware:
    enabled: true
    context_window: 3   # Consider previous N rounds of dialogue
    
  # Personalized retrieval
  personalization:
    enabled: false
    user_profile_weight: 0.2
    
  # Multilingual support
  multilingual:
    enabled: false
    languages: ["en", "zh", "es"]

# Performance Optimization
optimization:
  # Batch processing
  batch_processing:
    enabled: true
    batch_size: 32
    
  # GPU acceleration
  gpu_acceleration:
    enabled: true
    device: "cuda:0"
    
  # Index optimization
  index_optimization:
    type: "IVF"         # IVF, HNSW, LSH
    nlist: 100          # IVF parameters
    nprobe: 10          # Search parameters
